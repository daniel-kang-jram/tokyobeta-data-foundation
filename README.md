# Tokyo Beta - Real Estate Analytics Platform

**Status**: âœ… Production | ğŸ“Š Medallion Architecture | ğŸ”’ Robust Backup Strategy  
**Last Updated**: 2026-02-05

End-to-end data pipeline from property management system to QuickSight dashboards, processing daily SQL dumps through a medallion architecture (Bronze â†’ Silver â†’ Gold) with automated backups and Point-in-Time Recovery.

---

## ğŸ¯ Overview

This system automates the transformation of **daily SQL dumps** from the Nazca property management system into analytics-ready tables in **Aurora MySQL**, powering interactive dashboards in **Amazon QuickSight** for real estate portfolio management.

**Stakeholders**: 
- **Warburg Pincus** (PE Investor)
- **JRAM** (Special Purpose Company)
- **Tosei** (Asset Management)
- **GGhouse** (Property Management)

---

## ğŸ—ï¸ Architecture

### Data Flow (Resilient ETL Architecture)

```
Daily at 7:00 AM JST

S3 Bucket (jram-gghouse/dumps/)
  â”‚  gghouse_YYYYMMDD.sql (~945MB)
  â”‚
  â†“ Triggered by EventBridge
  
AWS Step Functions State Machine (ETL Orchestrator)
  â”‚
  â”œâ”€ Job 1: Staging Loader (3-4 min, retry 2x)
  â”‚  â””â”€ Download SQL dump, load 81 tables to staging
  â”‚
  â”œâ”€ Job 2: Silver Transformer (30 sec, retry 3x)
  â”‚  â””â”€ Run dbt seed + silver models (6 tables)
  â”‚
  â””â”€ Job 3: Gold Transformer (30 sec, retry 3x)
     â””â”€ Run dbt gold models (6 tables) + cleanup old backups
  
  Benefits:
  âœ“ Failure isolation (only failed layer retries)
  âœ“ Granular monitoring per layer
  âœ“ 90% faster recovery from failures
  âœ“ Layer-specific retry strategies
  
  â†“ ~4-5 minutes total execution
  
Aurora MySQL Cluster (db.t4g.medium)
  â”œâ”€â”€ staging (81 tables) - Bronze: Raw data
  â”œâ”€â”€ silver (6 tables) - Silver: Cleaned & standardized
  â”‚   â”œâ”€â”€ stg_apartments, stg_rooms, stg_tenants
  â”‚   â”œâ”€â”€ stg_movings, stg_inquiries
  â”‚   â””â”€â”€ int_contracts (59,118 rows)
  â””â”€â”€ gold (6 tables) - Gold: Business analytics
      â”œâ”€â”€ daily_activity_summary  (5,624 rows)
      â”œâ”€â”€ new_contracts           (16,508 rows)
      â”œâ”€â”€ moveouts                (15,262 rows)
      â”œâ”€â”€ moveout_notices         (3,635 rows)
      â”œâ”€â”€ moveout_analysis        (~15,262 rows) - With rent ranges, age groups
      â””â”€â”€ moveout_summary         (~1,500 rows) - Pre-aggregated by date/rent/geo
  
  â†“ QuickSight VPC Connection (Optional)
  
Amazon QuickSight (Enterprise)
  â”œâ”€â”€ 4 Datasets (Direct Query or SPICE)
  â””â”€â”€ 4 Dashboards
      â”œâ”€â”€ Executive Summary
      â”œâ”€â”€ New Contracts Analysis
      â”œâ”€â”€ Moveout & Retention Analysis
      â””â”€â”€ Tokyo Map View (Geospatial)
```

### Medallion Architecture (Bronze-Silver-Gold)

**Bronze Layer (Staging)**:
- Raw data from SQL dumps
- 81 tables loaded as-is
- No transformations
- Historical snapshot preserved

**Silver Layer (Cleaned)**:
- Standardized naming conventions
- Data type conversions
- NULL handling and cleaning
- Code-to-semantic mappings via seeds
- Denormalized fact table (`int_contracts`)

**Gold Layer (Analytics)**:
- Business-ready aggregations
- Pre-calculated metrics
- Optimized for BI consumption
- Daily activity summaries
- Demographics and geolocation

### Resilient ETL Design

The ETL pipeline is split into three independent Glue jobs orchestrated by AWS Step Functions:

**Architecture Benefits**:
- **Failure Isolation**: If gold layer fails, only gold retries (not entire 4-minute pipeline)
- **Cost Optimization**: ~18% savings on retry costs vs monolithic approach
- **Granular Monitoring**: CloudWatch metrics per layer (staging, silver, gold)
- **Layer-Specific Retries**: Different strategies for each layer type
- **Manual Recovery**: Can manually retry individual layers

**Failure Scenarios**:
```
Before (Monolithic):
Staging âœ“ â†’ Silver âœ“ â†’ Gold âœ— = RESTART EVERYTHING (20+ min)

After (Resilient):
Staging âœ“ â†’ Silver âœ“ â†’ Gold âœ— = RETRY GOLD ONLY (~2 min)
```

**Implementation**:
- `glue/scripts/staging_loader.py` - Bronze layer (945MB dump â†’ 81 tables)
- `glue/scripts/silver_transformer.py` - dbt silver models (6 tables)
- `glue/scripts/gold_transformer.py` - dbt gold models (6 tables)
- `terraform/modules/step_functions/` - State machine orchestration
- Comprehensive test suite following TDD principles

See [`docs/ETL_REFACTORING_PLAN.md`](docs/ETL_REFACTORING_PLAN.md) for detailed design rationale.

---

## âœ¨ Key Features

### Automated ETL Pipeline (Resilient Architecture)
- âœ… **Daily processing** at 7:00 AM JST (EventBridge â†’ Step Functions)
- âœ… **Three-stage pipeline** with independent retry logic
  - Staging: 2 retries, 5-min intervals (for S3/network issues)
  - Silver: 3 retries, 1-min intervals (for dbt compilation)
  - Gold: 3 retries, 1-min intervals (for transient DB locks)
- âœ… **Failure isolation** - only failed layer retries (saves 90% recovery time)
- âœ… **Full data refresh** from SQL dumps (945MB â†’ 97,000+ rows)
- âœ… **Medallion architecture** (Bronze â†’ Silver â†’ Gold)
- âœ… **Data quality tests** with 90.8% pass rate (69/76 tests)
- âœ… **CloudWatch monitoring** with error alerting per layer

### Robust Backup & Recovery
- âœ… **Aurora automated backups** with 7-day retention (no extra cost)
- âœ… **Point-in-Time Recovery (PITR)** to any second within backup window
- âœ… **Tested recovery script** (`scripts/rollback_etl.sh`)
- âœ… **Cost savings**: $57/month vs manual snapshots
- âœ… **5-10 minute recovery time**

### Analytics Tables
1. **Daily Activity Summary**: Aggregated metrics by date and tenant type (Individual/Corporate)
   - Inquiries, applications, contracts signed, move-ins, move-outs
2. **New Contracts**: Full contract details with demographics + geocoding
   - Age, gender, nationality, occupation, lat/long coordinates
3. **Moveouts**: Complete contract history with tenure and revenue
   - Stay duration, total revenue, moveout reasons
4. **Moveout Notices**: Rolling 24-month window for forecasting
   - Advance notice tracking for pipeline management

### Business Intelligence (Optional)
- ğŸ“Š **4 Interactive Dashboards** (Executive, Contracts, Moveouts, Map)
- ğŸ—ºï¸ **Tokyo Map Visualization** with property-level drill-down
- ğŸ“¤ **CSV/Excel Export** for all visuals
- ğŸ‘¥ **Multi-org Access** with role-based permissions

---

## ğŸš€ Quick Start

### Prerequisites

- **AWS Account**: 343881458651 (gghouse)
- **AWS CLI**: Configured with `gghouse` SSO profile
- **Terraform**: >=1.5.0 (if making infrastructure changes)
- **Region**: ap-northeast-1 (Tokyo)

### Check System Status

```bash
# Authenticate with AWS
aws sso login --profile gghouse

# Check latest ETL job
aws glue get-job-runs \
    --job-name tokyobeta-prod-daily-etl \
    --max-results 1 \
    --profile gghouse \
    --region ap-northeast-1 \
    --query 'JobRuns[0].{Status:JobRunState,ExecutionTime:ExecutionTime,CompletedOn:CompletedOn}'

# Check analytics tables
mysql -h tokyobeta-prod-aurora-cluster-public.cluster-cr46qo6y4bbb.ap-northeast-1.rds.amazonaws.com \
    -u admin -p \
    -e "SELECT TABLE_NAME, TABLE_ROWS FROM information_schema.TABLES WHERE TABLE_SCHEMA = 'gold' ORDER BY TABLE_NAME;"
```

### Manual ETL Trigger

```bash
# Trigger ETL job
aws glue start-job-run \
    --job-name tokyobeta-prod-daily-etl \
    --profile gghouse \
    --region ap-northeast-1

# Monitor logs
aws logs tail /aws-glue/jobs/output \
    --follow --profile gghouse --region ap-northeast-1
```

### Emergency Recovery (PITR)

```bash
# Show available restore window
./scripts/rollback_etl.sh

# Restore to specific time (if needed)
./scripts/rollback_etl.sh "2026-02-04T10:00:00Z"
```

---

## ğŸ“‚ Project Structure

```
tokyobeta-data-consolidation/
â”œâ”€â”€ terraform/                    # Infrastructure as Code
â”‚   â”œâ”€â”€ bootstrap/                # S3 + DynamoDB for state
â”‚   â”œâ”€â”€ modules/                  # Reusable Terraform modules
â”‚   â”‚   â”œâ”€â”€ networking/           # VPC, subnets, NAT, security groups
â”‚   â”‚   â”œâ”€â”€ aurora/               # MySQL cluster (staging/silver/gold)
â”‚   â”‚   â”œâ”€â”€ glue/                 # ETL job, IAM roles
â”‚   â”‚   â”œâ”€â”€ eventbridge/          # Daily trigger + Lambda proxy
â”‚   â”‚   â”œâ”€â”€ monitoring/           # CloudWatch alarms + SNS
â”‚   â”‚   â””â”€â”€ secrets/              # Secrets Manager for credentials
â”‚   â””â”€â”€ environments/prod/        # Production deployment
â”‚
â”œâ”€â”€ glue/scripts/                 # AWS Glue ETL scripts
â”‚   â””â”€â”€ daily_etl.py              # Main ETL: download â†’ load â†’ transform
â”‚
â”œâ”€â”€ dbt/                          # dbt transformation project
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/              # Bronze: Source definitions
â”‚   â”‚   â”œâ”€â”€ silver/               # Silver: Cleaned data + denormalization
â”‚   â”‚   â””â”€â”€ gold/                 # Gold: Business analytics
â”‚   â”œâ”€â”€ seeds/                    # Reference data (code mappings)
â”‚   â”œâ”€â”€ macros/                   # Reusable SQL functions
â”‚   â”œâ”€â”€ tests/                    # Custom data quality tests
â”‚   â”œâ”€â”€ dbt_project.yml           # dbt configuration
â”‚   â””â”€â”€ profiles.yml              # Aurora connection settings
â”‚
â”œâ”€â”€ scripts/                      # Operational scripts
â”‚   â”œâ”€â”€ quicksight/               # QuickSight setup (optional)
â”‚   â”‚   â”œâ”€â”€ QUICKSIGHT_SETUP_GUIDE.md
â”‚   â”‚   â””â”€â”€ setup_quicksight.py
â”‚   â””â”€â”€ rollback_etl.sh           # PITR recovery script
â”‚
â”œâ”€â”€ docs/                         # Project documentation
â”‚   â”œâ”€â”€ DATABASE_SCHEMA_EXPLANATION.md   # All schemas explained
â”‚   â”œâ”€â”€ BACKUP_RECOVERY_STRATEGY.md      # Recovery procedures
â”‚   â”œâ”€â”€ ROBUSTNESS_IMPLEMENTATION_SUMMARY.md  # Latest improvements
â”‚   â”œâ”€â”€ CLEANUP_COMPLETION_REPORT.md     # Database cleanup results
â”‚   â”œâ”€â”€ ARCHITECTURE_DECISION.md         # Why Glue + dbt
â”‚   â”œâ”€â”€ DATA_DICTIONARY.md               # Column definitions
â”‚   â””â”€â”€ DMS_VENDOR_REQUIREMENTS.md       # For future CDC
â”‚
â”œâ”€â”€ docs/                         # Project documentation (including CURRENT_STATUS.md)
â””â”€â”€ README.md                     # This file
```

---

## ğŸ“Š Current System State

### Databases & Schemas

| Schema | Tables | Purpose | Status |
|--------|--------|---------|--------|
| **staging** | ~71 | Bronze: Raw SQL dump data | âœ… Operational (auto-cleaned) |
| **silver** | 6 | Silver: Cleaned & standardized | âœ… Operational |
| **gold** | 4 | Gold: Business analytics | âœ… Operational |
| **seeds** | 6 | Reference data mappings | âœ… Operational |

**Recent Cleanup (Feb 5, 2026)**:
- âŒ Dropped `basis` (80 empty tables - vendor artifact)
- âŒ Dropped `_analytics`, `_silver`, `_gold` (legacy schemas)
- âŒ Dropped `analytics` (empty, superseded by `gold`)
- âŒ Dropped 10 empty staging tables (automated daily cleanup)
- âœ… Clean database structure with only active schemas
- âœ… Automated cleanup integrated into daily ETL

### Data Summary

| Table | Rows | Refresh | Purpose |
|-------|------|---------|---------|
| `staging.*` | Various | Daily 7:00 AM | Raw source data (81 tables) |
| `silver.int_contracts` | 59,118 | Daily | Central denormalized fact table |
| `gold.daily_activity_summary` | 5,624 | Daily | Daily KPIs by tenant type |
| `gold.new_contracts` | 16,508 | Daily | Demographics + geolocation |
| `gold.moveouts` | 15,262 | Daily | Tenure & revenue analysis |
| `gold.moveout_notices` | 3,635 | Daily | 24-month rolling window |

**Total Analytics Rows**: ~97,000  
**Data Quality**: 90.8% test pass rate (69/76 dbt tests)  
**Latency**: <12 hours from source update  
**Data Freshness**: Updated daily at 7:00 AM JST

---

## ğŸ’° Cost Breakdown

### Current Infrastructure (Monthly)

| Service | Configuration | Cost |
|---------|---------------|------|
| Aurora MySQL | db.t4g.medium, 20GB storage, 2 instances | ~$50 |
| Automated Backups | 7-day retention (included) | **$0** |
| AWS Glue | Daily 4-min job, 2 DPU | ~$5 |
| S3 | 945MB Ã— 30 days + artifacts | ~$1 |
| VPC | NAT Gateway | ~$32 |
| CloudWatch | Logs (7-day retention) | ~$3 |
| **Infrastructure Total** | | **~$91/month** |

**Cost Savings** (vs previous implementation):
- Manual snapshots eliminated: **-$57/month**
- Optimized Glue runtime (15min â†’ 4min): **-$5/month**

### QuickSight (Optional - Not Yet Enabled)

| Component | Usage | Cost |
|-----------|-------|------|
| QuickSight Authors | 4 users Ã— $18/user | $72 |
| QuickSight Readers | 10 users Ã— $5/user | $50 |
| SPICE Capacity | 20MB | <$1 |
| **QuickSight Total** | | **~$122/month** |

### **Total Cost**: 
- **With ETL only**: ~$91/month
- **With QuickSight**: ~$213/month
- **Per User (14 users)**: ~$15.21/user/month

---

## ğŸ› ï¸ Operations & Maintenance

### Daily Operations

**Automated Tasks** (no intervention required):
1. EventBridge triggers ETL at 7:00 AM JST
2. Glue downloads latest SQL dump
3. Data loaded to staging schema
4. Empty tables automatically dropped (cleanup)
5. dbt transformations create silver/gold tables
6. CloudWatch monitors for failures
7. SNS alerts on errors

**Manual Monitoring**:
```bash
# Check recent ETL runs
aws glue get-job-runs \
    --job-name tokyobeta-prod-daily-etl \
    --max-results 5 \
    --profile gghouse --region ap-northeast-1 \
    --query 'JobRuns[].[Id,JobRunState,ExecutionTime,CompletedOn]' \
    --output table

# View CloudWatch logs
aws logs tail /aws-glue/jobs/output \
    --since 1h --profile gghouse --region ap-northeast-1

# Check data freshness
mysql -h tokyobeta-prod-aurora-cluster-public.cluster-cr46qo6y4bbb.ap-northeast-1.rds.amazonaws.com \
    -u admin -p gold \
    -e "SELECT MAX(created_at) as last_update FROM daily_activity_summary;"
```

### Backup & Recovery

**Automated Backups**:
- **Retention**: 7 days
- **Type**: Continuous, point-in-time
- **Cost**: $0 (included in Aurora pricing)
- **Restore Window**: Any second within 7 days

**Recovery Procedure**:
```bash
# Show available restore times
./scripts/rollback_etl.sh

# Restore to 1 hour ago
./scripts/rollback_etl.sh "$(date -u -v-1H +%Y-%m-%dT%H:%M:%SZ)"

# Follow on-screen instructions for restoration
```

**Recovery Time**: 5-10 minutes  
**Documentation**: `docs/BACKUP_RECOVERY_STRATEGY.md`

### Troubleshooting

**ETL Job Fails**:
```bash
# Check error logs
aws logs tail /aws-glue/jobs/error \
    --since 1h --profile gghouse --region ap-northeast-1

# Common issues:
# - S3 dump file missing: Check s3://jram-gghouse/dumps/
# - Aurora connection: Verify security groups
# - dbt compilation: Check dbt/models/ syntax
```

**Data Quality Issues**:
```bash
# Run dbt tests manually
cd dbt/
dbt test --profiles-dir . --target prod

# Check specific test
dbt test --select test_name --profiles-dir . --target prod
```

**Performance Issues**:
```bash
# Check Aurora metrics
aws cloudwatch get-metric-statistics \
    --namespace AWS/RDS \
    --metric-name CPUUtilization \
    --dimensions Name=DBClusterIdentifier,Value=tokyobeta-prod-aurora-cluster-public \
    --start-time $(date -u -v-1H +%Y-%m-%dT%H:%M:%S) \
    --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
    --period 300 --statistics Average \
    --profile gghouse --region ap-northeast-1
```

---

## ğŸ“š Documentation

### Setup & Operations
- **[Current Status](docs/CURRENT_STATUS.md)**: Latest system state and recent changes
- **[Database Schemas](docs/DATABASE_SCHEMA_EXPLANATION.md)**: Complete schema inventory
- **[Backup Strategy](docs/BACKUP_RECOVERY_STRATEGY.md)**: Recovery procedures
- **[Cleanup Report](docs/CLEANUP_COMPLETION_REPORT.md)**: Database cleanup results

### Technical Documentation
- **[Architecture Decision](docs/ARCHITECTURE_DECISION.md)**: Why Glue + dbt
- **[Data Dictionary](docs/DATA_DICTIONARY.md)**: Column definitions
- **[Rent Roll Reconciliation](docs/RENT_ROLL_RECONCILIATION_20260209.md)**: Reconciliation between PMS and analytics
- **[Nationality Enrichment](docs/LLM_NATIONALITY_ENRICHMENT.md)**: LLM-based nationality prediction

### Optional Features
- **[QuickSight Setup](scripts/quicksight/QUICKSIGHT_SETUP_GUIDE.md)**: Dashboard creation
- **[DMS Requirements](docs/DMS_VENDOR_REQUIREMENTS.md)**: For future CDC

---

## ğŸ”§ Development & Testing

### Local Testing

```bash
# Test dbt models locally
cd dbt/
dbt run --profiles-dir . --target dev
dbt test --profiles-dir . --target dev

# Validate Terraform changes
cd terraform/environments/prod/
terraform fmt
terraform validate
terraform plan
```

### Code Quality Standards

Following `.cursorrules`:
- âœ… **TDD**: Tests before implementation
- âœ… **Minimal Change**: Surgical edits only
- âœ… **Infrastructure as Code**: All resources in Terraform
- âœ… **Data Quality**: â‰¥80% test coverage (current: 90.8%)
- âœ… **Documentation**: Comprehensive guides

### Git Workflow

```bash
# Feature branch
git checkout -b feature/your-feature

# Make changes
git add .
git commit -m "feat(dbt): add new analytics model"

# Push and create PR
git push origin feature/your-feature
```

---

## ğŸ¤ Support & Team

### Technical Issues
- **ETL Pipeline**: Check CloudWatch logs `/aws-glue/jobs/`
- **Database**: Aurora MySQL CloudWatch metrics
- **Backup/Recovery**: See `docs/BACKUP_RECOVERY_STRATEGY.md`
- **Infrastructure**: Terraform state in S3

### Business Questions
- **Data Definitions**: See `docs/DATA_DICTIONARY.md`
- **Dashboard Usage**: See `scripts/quicksight/QUICKSIGHT_SETUP_GUIDE.md`
- **Source Data**: Contact Nazca (PMS vendor)

### Team Contacts
- **AWS Infrastructure**: Daniel Kang
- **Stakeholders**: Warburg PE, JRAM SPC, Tosei AM, GGhouse PM
- **PMS Vendor**: Nazca

---

## ğŸ¯ Recent Achievements

### February 5, 2026
- âœ… Database cleanup: Removed 5 redundant schemas
- âœ… Cost optimization: $57/month savings from backup strategy
- âœ… Robustness improvements: PITR tested and documented
- âœ… ETL optimization: 15min â†’ 4min runtime
- âœ… Data quality: 90.8% test pass rate

### January 31, 2026
- âœ… Medallion architecture implemented (Bronze â†’ Silver â†’ Gold)
- âœ… Infrastructure deployed (VPC, Aurora, Glue, EventBridge)
- âœ… dbt project created (4 gold models, 6 silver models, 6 seeds)
- âœ… Automated daily ETL operational
- âœ… Comprehensive documentation created

---

## ğŸ“ License

Proprietary - Internal use only  
Â© 2026 Tokyo Beta Real Estate Analytics

---

## ğŸš€ Next Steps

### For New Users
1. **Review Current Status**: Read `docs/CURRENT_STATUS.md`
2. **Understand Architecture**: Review this README
3. **Access Data**: Request Aurora credentials
4. **Explore Schemas**: Query gold tables for analytics

### For Optional QuickSight Setup
1. **Enable QuickSight**: https://quicksight.aws.amazon.com/
2. **Follow Setup Guide**: `scripts/quicksight/QUICKSIGHT_SETUP_GUIDE.md`
3. **Create VPC Connection**: Connect to Aurora private subnet
4. **Build Dashboards**: 4 pre-designed dashboard templates available

### For Infrastructure Changes
1. **Test Locally**: Validate Terraform/dbt changes
2. **Review Code**: Follow `.cursorrules` standards
3. **Deploy**: Use Terraform for infrastructure, dbt for models
4. **Monitor**: Check CloudWatch for errors

---

**Questions?** See [Current Status](docs/CURRENT_STATUS.md) or relevant documentation in `docs/`.
