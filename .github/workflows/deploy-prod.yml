name: Deploy Prod

on:
  push:
    branches:
      - main
    paths:
      - 'terraform/**'
      - 'glue/scripts/**'
      - 'dbt/**'
  workflow_dispatch: {}

permissions:
  contents: read
  id-token: write

concurrency:
  group: tokyobeta-prod-deploy
  cancel-in-progress: false

jobs:
  deploy-prod:
    name: Deploy Infrastructure and Artifacts
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
    env:
      AWS_REGION: ap-northeast-1
      S3_ARTIFACT_BUCKET: jram-gghouse
      TERRAFORM_STATE_BUCKET: tokyobeta-terraform-state
      TERRAFORM_STATE_KEY: prod/terraform.tfstate
      TF_VAR_alert_email: ${{ secrets.TF_VAR_ALERT_EMAIL }}
      TF_VAR_alert_emails: '["jram-ggh@outlook.com","daniel.kang@jram.jp"]'
      TF_VAR_allowed_cidr_blocks: '["85.115.98.80/32","13.112.83.65/32","54.168.114.197/32"]'
      TF_VAR_artifact_release: ${{ github.sha }}
      TF_VAR_create_rds_cron_secret: "true"
      TF_VAR_manage_rds_cron_secret_value: "false"
      # Keep Evidence Basic Auth enabled in Terraform-managed CloudFront config.
      # Value should be a JSON map string, e.g. {"admin":"<password>"}.
      TF_VAR_evidence_auth_users: ${{ secrets.TF_VAR_EVIDENCE_AUTH_USERS }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Validate required Terraform variables
        run: |
          if [[ -z "${TF_VAR_alert_email}" ]]; then
            echo "::error::Missing Actions secret TF_VAR_ALERT_EMAIL (used as TF_VAR_alert_email)."
            exit 1
          fi
          if [[ -z "${TF_VAR_alert_emails}" ]]; then
            echo "::error::Missing TF_VAR_alert_emails."
            exit 1
          fi
          if [[ "${TF_VAR_alert_emails}" != *"daniel.kang@jram.jp"* ]]; then
            echo "::error::TF_VAR_alert_emails must include daniel.kang@jram.jp."
            exit 1
          fi
          if [[ -z "${TF_VAR_allowed_cidr_blocks}" ]]; then
            echo "::error::Missing TF_VAR_allowed_cidr_blocks."
            exit 1
          fi
          if [[ -z "${TF_VAR_artifact_release}" ]]; then
            echo "::error::Missing TF_VAR_artifact_release."
            exit 1
          fi
          if [[ "${TF_VAR_allowed_cidr_blocks}" != *"13.112.83.65/32"* ]]; then
            echo "::error::TF_VAR_allowed_cidr_blocks must include EC2 dump EIP 13.112.83.65/32."
            exit 1
          fi
          if [[ "${TF_VAR_allowed_cidr_blocks}" != *"54.168.114.197/32"* ]]; then
            echo "::error::TF_VAR_allowed_cidr_blocks must include V3 upstream IP 54.168.114.197/32."
            exit 1
          fi
          if [[ "${TF_VAR_manage_rds_cron_secret_value}" != "false" ]]; then
            echo "::error::TF_VAR_manage_rds_cron_secret_value must be false in production."
            exit 1
          fi
          if [[ "${TF_VAR_create_rds_cron_secret}" != "true" ]]; then
            echo "::error::TF_VAR_create_rds_cron_secret must be true in production."
            exit 1
          fi
          if [[ -z "${TF_VAR_evidence_auth_users}" ]]; then
            echo "::error::Missing Actions secret TF_VAR_EVIDENCE_AUTH_USERS (used as TF_VAR_evidence_auth_users)."
            exit 1
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::343881458651:role/tokyobeta-prod-github-actions-deploy
          aws-region: ${{ env.AWS_REGION }}

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Build freshness checker PyMySQL layer artifact
        run: |
          set -euo pipefail
          rm -f terraform/modules/monitoring/pymysql_layer.zip
          layer_build_dir="$(mktemp -d)"
          python -m pip install --upgrade pip
          python -m pip install --target "${layer_build_dir}/python" "pymysql==1.1.1"
          (
            cd "${layer_build_dir}"
            zip -qr "${GITHUB_WORKSPACE}/terraform/modules/monitoring/pymysql_layer.zip" python
          )
          if [[ ! -s terraform/modules/monitoring/pymysql_layer.zip ]]; then
            echo "::error::Failed to build terraform/modules/monitoring/pymysql_layer.zip."
            exit 1
          fi

      - name: Sync Glue scripts to S3
        run: |
          aws s3 sync glue/scripts s3://${S3_ARTIFACT_BUCKET}/glue-scripts/releases/${TF_VAR_artifact_release}/ \
            --exclude "*" --include "*.py" --delete

      - name: Install dbt CLI
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.7.0 dbt-mysql==1.7.0 protobuf==4.25.3

      - name: Sync dbt project to S3
        run: |
          cd dbt
          dbt deps
          cd ..
          aws s3 sync dbt s3://${S3_ARTIFACT_BUCKET}/dbt-project/releases/${TF_VAR_artifact_release}/ \
            --exclude ".user.yml" \
            --exclude "target/*" \
            --exclude ".venv/*" \
            --exclude "logs/*" \
            --delete

      - name: Verify remote Terraform state exists
        run: |
          if ! aws s3api head-bucket --bucket ${S3_ARTIFACT_BUCKET} > /dev/null 2>&1; then
            echo "::error::S3 artifact bucket missing: s3://${S3_ARTIFACT_BUCKET}."
            exit 1
          fi

          if ! aws s3api head-bucket --bucket ${TERRAFORM_STATE_BUCKET} > /dev/null 2>&1; then
            echo "::error::Terraform state bucket missing: s3://${TERRAFORM_STATE_BUCKET}. Create bootstrap state backend first."
            exit 1
          fi

          if ! aws dynamodb describe-table --table-name tokyobeta-terraform-locks --region ${AWS_REGION} > /dev/null 2>&1; then
            echo "::error::Terraform lock table missing: tokyobeta-terraform-locks. Create bootstrap lock table first."
            exit 1
          fi

          if ! aws s3api head-object --bucket ${TERRAFORM_STATE_BUCKET} --key ${TERRAFORM_STATE_KEY} > /dev/null 2>&1; then
            echo "::error::Remote Terraform state not found in s3://${TERRAFORM_STATE_BUCKET}/${TERRAFORM_STATE_KEY}. Run local migration first: cd terraform/environments/prod && terraform init -migrate-state."
            exit 1
          fi

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.5

      - name: Apply Terraform
        working-directory: terraform/environments/prod
        run: |
          set -euo pipefail
          terraform init

          # Import existing prod cron secret into Terraform state when it exists in AWS but not in state.
          CRON_SECRET_ID="tokyobeta/prod/rds/cron-credentials"
          CRON_SECRET_ADDR="module.secrets.aws_secretsmanager_secret.rds_cron_credentials[0]"
          if aws secretsmanager describe-secret --secret-id "${CRON_SECRET_ID}" >/dev/null 2>&1; then
            if ! terraform state list | grep -qx "${CRON_SECRET_ADDR}"; then
              echo "Importing existing cron secret into Terraform state: ${CRON_SECRET_ID}"
              terraform import "${CRON_SECRET_ADDR}" "${CRON_SECRET_ID}"
            fi
          fi

          terraform plan -out=prod.tfplan
          terraform show -json prod.tfplan > prod.tfplan.json

          DELETE_ONLY_ADDRESSES="$(jq -r '.resource_changes[]? | select((.change.actions | index("delete")) and (.change.actions | index("create") | not)) | .address' prod.tfplan.json)"
          if [[ -n "${DELETE_ONLY_ADDRESSES}" ]]; then
            echo "::error::Terraform plan contains delete-only actions. Refusing apply in production."
            echo "${DELETE_ONLY_ADDRESSES}" | sed 's/^/ - /'
            exit 1
          fi

          set +e
          terraform apply -auto-approve prod.tfplan 2>&1 | tee terraform_apply.log
          APPLY_STATUS=${PIPESTATUS[0]}
          set -e

          if [ "${APPLY_STATUS}" -ne 0 ]; then
            if grep -q "Error releasing the state lock" terraform_apply.log && \
               grep -q "failed to retrieve lock info" terraform_apply.log; then
              echo "Terraform lock release race detected. Retrying apply with -lock=false."
              terraform apply -auto-approve -lock=false prod.tfplan
              exit 0
            fi
            exit ${APPLY_STATUS}
          fi

      - name: Post-deploy conformance checks
        run: |
          set -euo pipefail

          TOPIC_ARN="arn:aws:sns:${AWS_REGION}:343881458651:tokyobeta-prod-dashboard-etl-alerts"
          RULE_NAME="tokyobeta-prod-glue-job-state-failures"
          GLUE_ROLE_NAME="tokyobeta-prod-glue-service-role"
          FRESHNESS_FN="tokyobeta-prod-table-freshness-checker"

          policy_json="$(aws iam get-role-policy \
            --role-name "${GLUE_ROLE_NAME}" \
            --policy-name "tokyobeta-prod-glue-policy" \
            --query 'PolicyDocument' \
            --output json)"
          echo "${policy_json}" | jq -e '
            .Statement
            | map(.Action)
            | flatten
            | index("s3:GetObjectTagging")
          ' >/dev/null
          echo "${policy_json}" | jq -e '
            .Statement
            | map(.Action)
            | flatten
            | index("s3:PutObjectTagging")
          ' >/dev/null

          layer_count="$(aws lambda get-function-configuration \
            --function-name "${FRESHNESS_FN}" \
            --query 'length(Layers)' \
            --output text)"
          if [[ "${layer_count}" == "None" || "${layer_count}" -lt 1 ]]; then
            echo "::error::Freshness checker Lambda has no layers attached."
            exit 1
          fi

          aws events describe-rule --name "${RULE_NAME}" >/dev/null
          target_count="$(aws events list-targets-by-rule \
            --rule "${RULE_NAME}" \
            --query "length(Targets[?Arn=='${TOPIC_ARN}'])" \
            --output text)"
          if [[ "${target_count}" -lt 1 ]]; then
            echo "::error::Glue failure EventBridge rule is not targeting SNS topic."
            exit 1
          fi

          subs_json="$(aws sns list-subscriptions-by-topic --topic-arn "${TOPIC_ARN}" --output json)"
          for endpoint in "daniel.kang@jram.jp" "jram-ggh@outlook.com"; do
            arn="$(echo "${subs_json}" | jq -r --arg endpoint "${endpoint}" '.Subscriptions[] | select(.Endpoint==$endpoint) | .SubscriptionArn' | head -n 1)"
            if [[ -z "${arn}" || "${arn}" == "PendingConfirmation" ]]; then
              echo "::error::SNS subscription for ${endpoint} is missing or pending."
              exit 1
            fi
          done

      - name: Freshness checker smoke test
        run: |
          set -euo pipefail
          output_file="$(mktemp)"
          aws lambda invoke \
            --function-name tokyobeta-prod-table-freshness-checker \
            --payload '{}' \
            "${output_file}" >/dev/null

          if jq -e '.errorMessage' "${output_file}" >/dev/null 2>&1; then
            echo "::error::Freshness checker invocation returned runtime error."
            cat "${output_file}"
            exit 1
          fi

          body_json="$(jq -r '.body // empty' "${output_file}")"
          if [[ -z "${body_json}" ]]; then
            echo "::error::Freshness checker response body is empty."
            cat "${output_file}"
            exit 1
          fi

          db_checks_skipped="$(echo "${body_json}" | jq -r '.db_checks_skipped')"
          if [[ "${db_checks_skipped}" != "false" ]]; then
            echo "::error::Freshness checker smoke test indicates DB checks were skipped."
            cat "${output_file}"
            exit 1
          fi
